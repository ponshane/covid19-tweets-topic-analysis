{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from codebase.utils import MongoConnector \n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.corpora import Dictionary, MmCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileTag = \"FirstWeek-March-Tweets\"\n",
    "corpora_path = \"./corpora/\"\n",
    "model_path = \"./models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1, build Dictionary object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = MongoConnector(\"./config.ini\")\n",
    "conn.get_collection_cursor(\"FirstWeek_March\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.2 s, sys: 482 ms, total: 43.7 s\n",
      "Wall time: 56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = {\"tokens\":{\"$exists\": True}}\n",
    "dct = Dictionary()\n",
    "for doc in conn.data_streaming_from_collection(query=query):\n",
    "    token_f = [x for x in doc[\"tokens\"] if len(x) > 1]\n",
    "    dct.add_documents([token_f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original size of vocabs: 335223\n",
      "Truncated size of vocabs: 29667\n"
     ]
    }
   ],
   "source": [
    "print(\"Original size of vocabs: {}\".format(len(dct)))\n",
    "# control the vocabulary\n",
    "dct.filter_extremes(no_below=20, no_above=0.5, keep_n=len(dct), keep_tokens=None)\n",
    "print(\"Truncated size of vocabs: {}\".format(len(dct)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2, apply Tf-IDF representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 929 ms, total: 37.5 s\n",
      "Wall time: 45.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = {\"tokens\":{\"$exists\": True}}\n",
    "bow_corpus = []\n",
    "meta_wf = open(\"{}{}-Meta.csv\".format(corpora_path, fileTag),\"w\")\n",
    "meta_wf.write(\"position_index,id_str,created_time\\n\")\n",
    "position_index = 0\n",
    "for doc in conn.data_streaming_from_collection(query=query):\n",
    "    # gensim's Dictionary.doc2bow will ignore words that are not in dictionary by default\n",
    "    bow_per_doc = dct.doc2bow(doc[\"tokens\"])\n",
    "    if len(bow_per_doc) > 4:\n",
    "        timestamp = doc[\"created_at\"].strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        meta_wf.write(\"{},{},{}\\n\".format(position_index, doc[\"id_str\"], timestamp))\n",
    "        bow_corpus.append(bow_per_doc)\n",
    "        position_index += 1\n",
    "meta_wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 s, sys: 0 ns, total: 2.21 s\n",
      "Wall time: 2.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_model = TfidfModel(bow_corpus)  # fit model\n",
    "tfidf_corpus = tfidf_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3, train NMF to extract topic pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nmf = Nmf(tfidf_corpus, id2word=dct, num_topics=50)\n",
    "# CPU times: user 21min 12s, sys: 12min, total: 33min 13s\n",
    "# Wall time: 5min 29s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('county', 0.14236108682730447),\n",
       " ('officials', 0.019101592353724235),\n",
       " ('king', 0.018942966867407436),\n",
       " ('two', 0.01594921330650367),\n",
       " ('presumptive', 0.014868525580645197),\n",
       " ('santa', 0.012602169478004594),\n",
       " ('questions', 0.012228678584015079),\n",
       " ('florida', 0.011518394265381204),\n",
       " ('montgomery', 0.009187398302580222),\n",
       " ('new', 0.008964702096575038),\n",
       " ('man', 0.008872473133647307),\n",
       " ('broward', 0.008868353411455773),\n",
       " ('clara', 0.008840548435683908),\n",
       " ('resident', 0.007922327904062918),\n",
       " ('lee', 0.007636380220626515),\n",
       " ('los', 0.007213491226627287),\n",
       " ('angeles', 0.007131223085317641),\n",
       " ('department', 0.00705121820635023),\n",
       " ('residents', 0.0069208504385192245),\n",
       " ('positive', 0.006912661213467376)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get phi of a topic\n",
    "nmf.show_topic(topicid=9,topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 0.10944433115677271),\n",
       " (21, 0.021792774115770488),\n",
       " (24, 0.8298059263318602),\n",
       " (34, 0.015225289333366417)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get theta of a document\n",
    "nmf[tfidf_corpus[7]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4, Model persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dct.save('{}{}.dict'.format(corpora_path,fileTag))\n",
    "MmCorpus.serialize('{}{}-tf-idf.mm'.format(corpora_path,fileTag), tfidf_corpus)\n",
    "\n",
    "tfidf_model.save('{}{}-tf-idf.model'.format(model_path,fileTag))\n",
    "\n",
    "model_suffix = \"-50topics\"\n",
    "nmf.save(\"{}{}{}.model\".format(model_path,fileTag,model_suffix))\n",
    "\n",
    "# dct = Dictionary.load('dictionary.dict')\n",
    "# tfidf_corpus = MmCorpus.load('corpus.mm')\n",
    "# nmf = Nmf.load('topic.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HealthV",
   "language": "python",
   "name": "healthv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

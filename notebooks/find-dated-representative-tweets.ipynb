{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0a6c65a754d61e1d96737eaa654af461ca99a8f5ca05f699efc52d45053a70eb4",
   "display_name": "Python 3.7.6 64-bit ('HealthV': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this jupyter is used for analyzing and drawing the topics & sentiments inferred by OneModel using 2 months vaccine-related tweets \n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from codebase.topic_utilities import dtm_csv_to_pd_df, calculate_topic_ratios\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "# 1 Create Dated Document-Topic Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed params\n",
    "corpora_path = \"../corpora/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "# params\n",
    "fileTag_list = [\"First-and-SecondWeek-Tweets-Rolling\",\"Third-and-FourthWeek-Tweets-Rolling\",\\\n",
    "    \"Fifth-and-SixthWeek-Tweets-Rolling\", \"Seventh-and-EighthWeek-Tweets-Rolling\"]\n",
    "\n",
    "start_list = [\"2020-12-16\",\"2020-12-31\", \"2021-01-15\", \"2021-01-30\"]\n",
    "end_list = [\"2020-12-31\", \"2021-01-15\", \"2021-01-30\", \"2021-02-14\"]\n",
    "\n",
    "num_topics = 50\n",
    "model_suffix = \"-{}topics\".format(num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dated_dtm(dtm, metadata, start, end):\n",
    "    # drop duplicated tweets \n",
    "    metadata.drop_duplicates(subset=\"id_str\", inplace=True)\n",
    "    # merge with metadata for fecthing date\n",
    "    df = dtm.merge(metadata, on=\"position_index\", how=\"right\")\n",
    "    df['preDate'] = pd.to_datetime(df['created_time'])\n",
    "    # format the Date column for grouping conveniently\n",
    "    df[\"Date\"] = df[\"preDate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    # drop position_index, created_time, preDate\n",
    "    df = df.drop(['position_index', 'created_time', 'preDate'], axis=1)\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_of_dfs = []\n",
    "for fileTag, start, end in zip(fileTag_list, start_list, end_list):\n",
    "    \n",
    "    print(\"Start {} from {} to {}.\".format(fileTag, start, end))\n",
    "\n",
    "    metadata_filename = \"{}{}-Meta.csv\".format(corpora_path, fileTag)\n",
    "    # Read back data from csv files\n",
    "    metadata = pd.read_csv(metadata_filename)\n",
    "    doc_topic_matrix_filename = \"{}{}{}-dtm.csv\".format(model_path, fileTag, model_suffix)\n",
    "    dtm = dtm_csv_to_pd_df(doc_topic_matrix_filename)\n",
    "    list_of_dfs.append(return_dated_dtm(dtm, metadata, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dated_dtm = pd.concat(list_of_dfs)\n",
    "dated_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dated_dtm.to_pickle(\"../models/dated-dtm/2-months-50topics-dated-dtm.pkl\")\n",
    "dated_dtm = pd.read_pickle(\"../models/dated-dtm/2-months-50topics-dated-dtm.pkl\")"
   ]
  },
  {
   "source": [
    "# 2 Select Date sub matrix and Representative Tweets of a Topic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                     id_str        Date         9\n",
       "571682  1340369231100194820  2020-12-19  1.000000\n",
       "690205  1340355367017000961  2020-12-19  0.986842\n",
       "623005  1340379244837408768  2020-12-19  0.985944\n",
       "687182  1340325199527301120  2020-12-19  0.980553\n",
       "641168  1340353303075561472  2020-12-19  0.977436\n",
       "...                     ...         ...       ...\n",
       "695727  1340268856808534017  2020-12-19  0.928789\n",
       "384096  1340105908907601920  2020-12-19  0.928210\n",
       "699074  1340388298527793153  2020-12-19  0.927419\n",
       "631839  1340323632946548737  2020-12-19  0.926927\n",
       "428825  1340122422364663808  2020-12-19  0.926606\n",
       "\n",
       "[100 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_str</th>\n      <th>Date</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>571682</th>\n      <td>1340369231100194820</td>\n      <td>2020-12-19</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>690205</th>\n      <td>1340355367017000961</td>\n      <td>2020-12-19</td>\n      <td>0.986842</td>\n    </tr>\n    <tr>\n      <th>623005</th>\n      <td>1340379244837408768</td>\n      <td>2020-12-19</td>\n      <td>0.985944</td>\n    </tr>\n    <tr>\n      <th>687182</th>\n      <td>1340325199527301120</td>\n      <td>2020-12-19</td>\n      <td>0.980553</td>\n    </tr>\n    <tr>\n      <th>641168</th>\n      <td>1340353303075561472</td>\n      <td>2020-12-19</td>\n      <td>0.977436</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>695727</th>\n      <td>1340268856808534017</td>\n      <td>2020-12-19</td>\n      <td>0.928789</td>\n    </tr>\n    <tr>\n      <th>384096</th>\n      <td>1340105908907601920</td>\n      <td>2020-12-19</td>\n      <td>0.928210</td>\n    </tr>\n    <tr>\n      <th>699074</th>\n      <td>1340388298527793153</td>\n      <td>2020-12-19</td>\n      <td>0.927419</td>\n    </tr>\n    <tr>\n      <th>631839</th>\n      <td>1340323632946548737</td>\n      <td>2020-12-19</td>\n      <td>0.926927</td>\n    </tr>\n    <tr>\n      <th>428825</th>\n      <td>1340122422364663808</td>\n      <td>2020-12-19</td>\n      <td>0.926606</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "target_date = \"2020-12-19\"\n",
    "target_topic = 9\n",
    "top_n_tweets = 100\n",
    "sub_dated_dtm = dated_dtm.loc[dated_dtm['Date'] == target_date]\n",
    "nL = sub_dated_dtm.nlargest(top_n_tweets, columns=target_topic)[[\"id_str\", \"Date\", target_topic]]\n",
    "nL\n"
   ]
  }
 ]
}
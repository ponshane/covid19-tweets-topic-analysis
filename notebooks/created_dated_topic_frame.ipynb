{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0a6c65a754d61e1d96737eaa654af461ca99a8f5ca05f699efc52d45053a70eb4",
   "display_name": "Python 3.7.6 64-bit ('HealthV': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this jupyter is used for analyzing and drawing the topics & sentiments inferred by OneModel using 2 months vaccine-related tweets \n",
    "\"\"\"\n",
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir\n",
    "from codebase.topic_utilities import dtm_csv_to_pd_df, calculate_topic_ratios\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed params\n",
    "corpora_path = \"../corpora/\"\n",
    "model_path = \"../models/\"\n",
    "\n",
    "# params\n",
    "fileTag_list = [\"First-and-SecondWeek-Tweets-Rolling\",\"Third-and-FourthWeek-Tweets-Rolling\",\\\n",
    "    \"Fifth-and-SixthWeek-Tweets-Rolling\", \"Seventh-and-EighthWeek-Tweets-Rolling\"]\n",
    "\n",
    "start_list = [\"2020-12-16\",\"2020-12-31\", \"2021-01-15\", \"2021-01-30\"]\n",
    "end_list = [\"2020-12-31\", \"2021-01-15\", \"2021-01-30\", \"2021-02-14\"]\n",
    "\n",
    "num_topics = 50\n",
    "model_suffix = \"-{}topics\".format(num_topics)"
   ]
  },
  {
   "source": [
    "# Generate Dated Tweets with Max Topic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dated_topic_frame(dtm, metadata, start, end):\n",
    "    df_max = dtm.idxmax(axis=1).to_frame().reset_index()\n",
    "    df_max.columns = [\"position_index\", \"max_topic\"]\n",
    "\n",
    "    # drop duplicated tweets \n",
    "    metadata.drop_duplicates(subset=\"id_str\", inplace=True)\n",
    "    # merge with metadata for fecthing date\n",
    "    df = df_max.merge(metadata, on=\"position_index\", how=\"right\")\n",
    "    df['preDate'] = pd.to_datetime(df['created_time'])\n",
    "    # format the Date column for grouping conveniently\n",
    "    df[\"Date\"] = df[\"preDate\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    # drop position_index, created_time, preDate\n",
    "    df = df.drop(['position_index', 'created_time', 'preDate'], axis=1)\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "list_of_dfs = []\n",
    "for fileTag, start, end in zip(fileTag_list, start_list, end_list):\n",
    "    \n",
    "    print(\"Start {} from {} to {}.\".format(fileTag, start, end))\n",
    "\n",
    "    metadata_filename = \"{}{}-Meta.csv\".format(corpora_path, fileTag)\n",
    "    # Read back data from csv files\n",
    "    metadata = pd.read_csv(metadata_filename)\n",
    "    doc_topic_matrix_filename = \"{}{}{}-dtm.csv\".format(model_path, fileTag, model_suffix)\n",
    "    dtm = dtm_csv_to_pd_df(doc_topic_matrix_filename)\n",
    "    list_of_dfs.append(return_dated_topic_frame(dtm, metadata, start, end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_dfs = pd.concat(list_of_dfs)\n",
    "# concat_dfs.to_pickle(\"../corpora/distinct_tweets/dated_distinct_tweets_dtm.pickle\")"
   ]
  }
 ]
}
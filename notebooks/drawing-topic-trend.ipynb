{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitae75879463b449beabd0fcd0729aeab1",
   "display_name": "Python 3.7.6 64-bit ('HealthV': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a6c65a754d61e1d96737eaa654af461ca99a8f5ca05f699efc52d45053a70eb4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this jupyter is used for analyzing and drawing the topics & sentiments inferred by OneModel using 2 months vaccine-related tweets \n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# Display figures inline in Jupyter notebook\n",
    "import seaborn as sns\n",
    "# Use seaborn style defaults and set the default figure size\n",
    "sns.set(rc={'figure.figsize':(11, 4)})"
   ]
  },
  {
   "source": [
    "# 0. Importe Dated Tweets with Max Topic Column"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dfs = pd.read_pickle(\"../corpora/distinct_tweets/dated_distinct_tweets_dtm.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dfs =  concat_dfs.drop([\"index\"], axis=1)\n",
    "concat_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat_dfs.reset_index()\n",
    "# concat_dfs = concat_dfs.set_index('Date')\n",
    "# concat_dfs.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily_counts = concat_dfs.groupby(\"Date\").size().loc[\"2020-12-16\":\"2021-02-13\"]\n",
    "# daily_counts.columns = ['count']\n",
    "# daily_counts = daily_counts.reset_index()\n",
    "# daily_counts = daily_counts.set_index('Date')"
   ]
  },
  {
   "source": [
    "## a. Count topic ratio in total (across 8 weeks)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_counts = concat_dfs['max_topic'].value_counts()\n",
    "for topic_idx in range(0, 50):\n",
    "    print(\"{:.2%}\".format(topic_counts[topic_idx]/concat_dfs.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_maxtopics_per_day(df_max):\n",
    "    \"\"\" This function is used to count topics per day for later drawing\n",
    "    \"\"\"\n",
    "    # groupby [date, top_topics] aggregate by count(id_str)\n",
    "    max_counts = df_max.groupby(['Date', 'max_topic']).agg({'id_str' : 'count'}).reset_index()\n",
    "    max_counts.columns = ['Date', 'topic_id', 'max_count']\n",
    "\n",
    "    # Count the number of individual documents per day\n",
    "    total_docs = df_max[['Date', 'id_str']].groupby('Date').agg({'id_str' : 'count'}).reset_index()\n",
    "    total_docs.columns = ['Date', 'total_docs']\n",
    "\n",
    "    # Combine the two dataframes\n",
    "    max_counts = max_counts.merge(total_docs, on='Date', how='left')\n",
    "    # Create a new column with the count per topic divided by the total docs per day\n",
    "    # Normalize\n",
    "    max_counts['prevalence'] = max_counts['max_count']/max_counts['total_docs']\n",
    "\n",
    "    # pivot to wide format\n",
    "    max_counts = max_counts[['Date', 'topic_id', 'prevalence']].pivot(index='Date',\\\n",
    "                                                                    columns='topic_id',\\\n",
    "                                                                    values='prevalence').fillna(0)\n",
    "\n",
    "    max_counts.index = pd.to_datetime(max_counts.index)\n",
    "    return max_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "max_counts = count_maxtopics_per_day(concat_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_label_dict = {0: \"Vaccination of Frontline Workers\",\n",
    "13: \"Access to Vaccines - Signing Up Online\",\n",
    "9: \"South African Variant\",\n",
    "21: \"Biden Stimulus Plan\",\n",
    "45: \"mRNA vaccines\",\n",
    "27: \"Complaints about pharm company profits\",\n",
    "26: \"Vaccine Conspiracy Theories online\",\n",
    "4: \"Trials in non mRNA vaccines\",\n",
    "31: \"Vaccine distribution in Canada\",\n",
    "2: \"Concerns about supply to reach heard immunity by summer\",\n",
    "36: \"Genetic concerns about vaccines and kids\",\n",
    "7: \"Low distribution of AstraZeneca vaccine\"}\n",
    "\n",
    "topic_reorder_dict = {0:1,\n",
    "13:2,\n",
    "9:3,\n",
    "21:4,\n",
    "45:5,\n",
    "27:6,\n",
    "26:7,\n",
    "4:8,\n",
    "31:9,\n",
    "2:10,\n",
    "36:11,\n",
    "7:12}"
   ]
  },
  {
   "source": [
    "# 1 Draw Topic Trend"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### a. Plot Multiple Topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase1 = ['0', '13', '9', '21', '45', '27']\n",
    "phrase2 = ['26', '4', '31', '2', '36', '7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2020-12-16'\n",
    "END = '2021-02-14'\n",
    "fig, ax = plt.subplots()\n",
    "for topic_id in phrase1:\n",
    "    ax.plot(max_counts.loc[START:END, int(topic_id)], label=\"Topic {}, {}\".format(topic_reorder_dict[int(topic_id)], topic_label_dict[int(topic_id)]))\n",
    "    date_form = DateFormatter(\"%m-%d\")\n",
    "    ax.xaxis.set_major_formatter(date_form) \n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax.legend(loc=9, bbox_to_anchor=(0.25, 1.6))\n",
    "    ax.set_ylabel('Prevalence of the Selected Topics per Day')\n",
    "    ax.set_title('Trends in Covid19 Discussion Topics')\n",
    "plt.savefig('../images/Topic-Trends-Phrase1.png', bbox_inches = 'tight', dpi=300)"
   ]
  },
  {
   "source": [
    "### b. Plot a Single Topic"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2020-12-16'\n",
    "END = '2021-02-14'\n",
    "# topic_id = 4\n",
    "for topic_id in phrase1+phrase2:\n",
    "    # Plot daily and weekly resampled time series together\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(max_counts.loc[START:END, int(topic_id)],\n",
    "    marker='.', linestyle='-', linewidth=0.5, label='Daily Prevalence of Topic {}, {}'.format(topic_reorder_dict[int(topic_id)], topic_label_dict[int(topic_id)]))\n",
    "    date_form = DateFormatter(\"%m-%d\")\n",
    "    ax.xaxis.set_major_formatter(date_form) \n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    ax.plot(max_counts.loc[START:END, int(topic_id)].resample('W').mean(),\n",
    "    marker='o', markersize=8, linestyle='-', label='Weekly Prevalence of Topic {}, {}'.format(topic_reorder_dict[int(topic_id)], topic_label_dict[int(topic_id)]))\n",
    "    ax.set_ylabel('Prevalence of the Selected Topic per Day')\n",
    "    ax.legend()\n",
    "    plt.savefig('../images/Trends-of-Topic-{}.png'.format(topic_reorder_dict[int(topic_id)]), dpi=300)"
   ]
  }
 ]
}